{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOIRAI Financial Time Series Training Prototype\n",
    "\n",
    "This notebook implements a prototype for training the MOIRAI model on financial time series data. We'll start with univariate training on SP500 data from 2000-2010, then progress to multivariate training with OHLCV and technical indicators.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Data Extraction and Preprocessing\n",
    "2. Feature Engineering\n",
    "3. Dataset Creation\n",
    "4. Model Configuration\n",
    "5. Training Loop\n",
    "6. Evaluation\n",
    "7. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from collections.abc import Generator\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# Data handling\n",
    "import datasets\n",
    "from datasets import Features, Sequence, Value\n",
    "\n",
    "# Technical indicators\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import lightning as L\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# uni2ts imports\n",
    "from uni2ts.model.moirai import MoiraiModule, MoiraiForecast, MoiraiFinetune\n",
    "from uni2ts.distribution import StudentTOutput, NormalOutput, NegativeBinomialOutput, LogNormalOutput, MixtureOutput\n",
    "from uni2ts.loss.packed import PackedNLLLoss\n",
    "from uni2ts.data.loader import DataLoader, PackCollate\n",
    "from uni2ts.eval_util.metrics import MedianMSE, MedianMAE\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ohlcv_data(asset_class, symbol, freq, start_year, end_year, start_month=1, end_month=12):\n",
    "    \"\"\"\n",
    "    Extract OHLCV data for a specific asset from the Parquet data lake.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    asset_class : str\n",
    "        Asset class (crypto, fx, equity, etc.)\n",
    "    symbol : str\n",
    "        Symbol or ticker\n",
    "    freq : str\n",
    "        Frequency (1min, 15min, 1h, 4h, 1d)\n",
    "    start_year, end_year : int\n",
    "        Start and end years\n",
    "    start_month, end_month : int\n",
    "        Start and end months (default: full year)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    polars.DataFrame\n",
    "        DataFrame containing the OHLCV data\n",
    "    \"\"\"\n",
    "    # Construct the path pattern\n",
    "    path_pattern = f\"/home/dev/data/ohlcv/asset_class={asset_class}/freq={freq}/symbol={symbol}/year={{{start_year}..{end_year}}}/month={{{start_month}..{end_month}}}/part.parquet\"\n",
    "    \n",
    "    # Scan the parquet files\n",
    "    scan = pl.scan_parquet(\n",
    "        path_pattern,\n",
    "        hive_partitioning=True,\n",
    "    )\n",
    "    \n",
    "    # Select and rename columns\n",
    "    df = scan.select(\n",
    "        pl.col(\"ts\"),\n",
    "        pl.col(\"open\"),\n",
    "        pl.col(\"high\"),\n",
    "        pl.col(\"low\"),\n",
    "        pl.col(\"close\"),\n",
    "        pl.col(\"volume\"),\n",
    "    ).sort(\"ts\").collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SP500 data from 2000 to 2010\n",
    "sp500_data = extract_ohlcv_data(\n",
    "    asset_class=\"index\", \n",
    "    symbol=\"SPX\", \n",
    "    freq=\"1d\", \n",
    "    start_year=2000, \n",
    "    end_year=2010\n",
    ")\n",
    "\n",
    "# Display the first few rows\n",
    "sp500_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Add technical indicators to OHLCV data.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Moving Averages\n",
    "    result_df['sma_5'] = ta.sma(result_df['close'], length=5)\n",
    "    result_df['sma_20'] = ta.sma(result_df['close'], length=20)\n",
    "    result_df['ema_5'] = ta.ema(result_df['close'], length=5)\n",
    "    result_df['ema_20'] = ta.ema(result_df['close'], length=20)\n",
    "    \n",
    "    # MACD\n",
    "    macd = ta.macd(result_df['close'])\n",
    "    result_df['macd'] = macd['MACD_12_26_9']\n",
    "    result_df['macd_signal'] = macd['MACDs_12_26_9']\n",
    "    \n",
    "    # RSI\n",
    "    result_df['rsi_14'] = ta.rsi(result_df['close'], length=14)\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bbands = ta.bbands(result_df['close'], length=20)\n",
    "    result_df['bb_upper'] = bbands['BBU_20_2.0']\n",
    "    result_df['bb_middle'] = bbands['BBM_20_2.0']\n",
    "    result_df['bb_lower'] = bbands['BBL_20_2.0']\n",
    "    \n",
    "    # Drop NaN values resulting from indicators calculation\n",
    "    result_df = result_df.dropna()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_univariate_dataset(df, target_col='close'):\n",
    "    \"\"\"\n",
    "    Create a univariate dataset for the MOIRAI model.\n",
    "    \"\"\"\n",
    "    def example_gen_func() -> Generator[dict[str, Any], None, None]:\n",
    "        yield {\n",
    "            \"target\": df[target_col].to_numpy(),  # array of shape (time,)\n",
    "            \"start\": df.index[0],\n",
    "            \"freq\": pd.infer_freq(df.index),\n",
    "            \"item_id\": \"SPX\",\n",
    "        }\n",
    "    \n",
    "    features = Features(\n",
    "        dict(\n",
    "            target=Sequence(Value(\"float32\")),\n",
    "            start=Value(\"timestamp[s]\"),\n",
    "            freq=Value(\"string\"),\n",
    "            item_id=Value(\"string\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    hf_dataset = datasets.Dataset.from_generator(example_gen_func, features=features)\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multivariate_dataset(df, target_col='close', feature_cols=None):\n",
    "    \"\"\"\n",
    "    Create a multivariate dataset for the MOIRAI model.\n",
    "    \"\"\"\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [col for col in df.columns if col != target_col]\n",
    "    \n",
    "    def multivar_example_gen_func() -> Generator[dict[str, Any], None, None]:\n",
    "        yield {\n",
    "            \"target\": df[[target_col]].to_numpy().T,  # array of shape (1, time)\n",
    "            \"feat_dynamic_real\": df[feature_cols].to_numpy().T,  # array of shape (features, time)\n",
    "            \"start\": df.index[0],\n",
    "            \"freq\": pd.infer_freq(df.index),\n",
    "            \"item_id\": \"SPX\",\n",
    "        }\n",
    "    \n",
    "    features = Features(\n",
    "        dict(\n",
    "            target=Sequence(Sequence(Value(\"float32\")), length=1),\n",
    "            feat_dynamic_real=Sequence(Sequence(Value(\"float32\")), length=len(feature_cols)),\n",
    "            start=Value(\"timestamp[s]\"),\n",
    "            freq=Value(\"string\"),\n",
    "            item_id=Value(\"string\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    hf_dataset = datasets.Dataset.from_generator(multivar_example_gen_func, features=features)\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_moirai_model(pretrained_model_name=\"Salesforce/moirai-1.1-R-base\"):\n",
    "    \"\"\"\n",
    "    Configure the MOIRAI model for financial time series forecasting.\n",
    "    \"\"\"\n",
    "    # Load the pretrained model\n",
    "    model = MoiraiModule.from_pretrained(pretrained_model_name)\n",
    "    \n",
    "    # Configure the model for financial time series\n",
    "    model_config = {\n",
    "        \"distr_output\": MixtureOutput(\n",
    "            components=[\n",
    "                StudentTOutput(),\n",
    "                NormalOutput(),\n",
    "                LogNormalOutput()\n",
    "            ]\n",
    "        ),\n",
    "        \"d_model\": 768,\n",
    "        \"num_layers\": 12,\n",
    "        \"patch_sizes\": [8, 16, 32, 64],\n",
    "        \"max_seq_len\": 512,\n",
    "        \"attn_dropout_p\": 0.1,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"scaling\": True\n",
    "    }\n",
    "    \n",
    "    return model, model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moirai_model(model, train_dataset, val_dataset=None, epochs=10, batch_size=32, learning_rate=1e-4):\n",
    "    \"\"\"\n",
    "    Train the MOIRAI model on financial time series data.\n",
    "    \"\"\"\n",
    "    # Configure the training\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=epochs,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=1,\n",
    "        precision=16 if torch.cuda.is_available() else 32,\n",
    "        gradient_clip_val=1.0\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, train_dataset, val_dataset)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Evaluate the MOIRAI model on test data.\n",
    "    \"\"\"\n",
    "    # Evaluate the model\n",
    "    metrics = {\n",
    "        \"mse\": MedianMSE(),\n",
    "        \"mae\": MedianMAE()\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results = {}\n",
    "    for name, metric in metrics.items():\n",
    "        results[name] = metric(model, test_dataset)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow\n",
    "def main():\n",
    "    # 1. Extract and preprocess data\n",
    "    sp500_data = extract_ohlcv_data(\n",
    "        asset_class=\"index\", \n",
    "        symbol=\"SPX\", \n",
    "        freq=\"1d\", \n",
    "        start_year=2000, \n",
    "        end_year=2010\n",
    "    )\n",
    "    \n",
    "    # Convert to pandas\n",
    "    sp500_df = sp500_data.to_pandas()\n",
    "    sp500_df.set_index('ts', inplace=True)\n",
    "    \n",
    "    # 2. Add technical indicators\n",
    "    sp500_df_features = add_technical_indicators(sp500_df)\n",
    "    \n",
    "    # 3. Create datasets\n",
    "    # Univariate dataset (close price only)\n",
    "    univariate_dataset = create_univariate_dataset(sp500_df_features)\n",
    "    univariate_dataset.save_to_disk(\"sp500_univariate_dataset\")\n",
    "    \n",
    "    # Multivariate dataset (close price + features)\n",
    "    feature_cols = ['open', 'high', 'low', 'volume', 'sma_5', 'sma_20', 'rsi_14', 'macd']\n",
    "    multivariate_dataset = create_multivariate_dataset(sp500_df_features, feature_cols=feature_cols)\n",
    "    multivariate_dataset.save_to_disk(\"sp500_multivariate_dataset\")\n",
    "    \n",
    "    # 4. Configure model\n",
    "    model, model_config = configure_moirai_model()\n",
    "    \n",
    "    # 5. Train model\n",
    "    # (Training would be done using the CLI for better configuration)\n",
    "    print(\"Training would be done using the CLI with the following command:\")\n",
    "    print(\"python -m cli.train -cp conf/finetune run_name=sp500_univariate model=moirai_1.1_R_base data=sp500_univariate\")\n",
    "    \n",
    "    print(\"\\nDatasets created and saved to disk:\")\n",
    "    print(\"- sp500_univariate_dataset\")\n",
    "    print(\"- sp500_multivariate_dataset\")\n",
    "    \n",
    "    return \"Workflow completed successfully\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
