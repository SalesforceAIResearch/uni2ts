{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386b60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the test but check for validation data before cleanup\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from src.uni2ts.data.builder.custom_financial_builder import IterativeFinancialDatasetBuilder\n",
    "from uni2ts.data.dataset import SampleTimeSeriesType\n",
    "from uni2ts.transform import Identity\n",
    "import tempfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53bc388c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using temporary directory: /tmp/uni2ts_financial_test_bcgzuqbs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baef74f357bb4179ac379fb7dadfd513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 1 samples\n",
      "\n",
      "1. Checking for validation data...\n",
      "Temporary files created: []\n",
      "✓ No validation files found in temporary directory\n",
      "\n",
      "2. Checking temporary directory structure...\n",
      "uni2ts_financial_test_bcgzuqbs/\n",
      "\n",
      "3. Verifying data structure...\n",
      "Sample keys: ['start', 'freq', 'item_id', 'target']\n",
      "Target shape info: 5 variates\n",
      "\n",
      "4. Checking for validation-related processing...\n",
      "✓ Builder only creates training data (no validation splits)\n",
      "✓ No date_offset or offset parameters used\n",
      "✓ No validation dataset generation in output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create temporary directory for testing\n",
    "temp_dir = tempfile.mkdtemp(prefix=\"uni2ts_financial_test_\")\n",
    "print(f\"Using temporary directory: {temp_dir}\")\n",
    "\n",
    "# Initialize the builder\n",
    "builder = IterativeFinancialDatasetBuilder(\n",
    "    data_path=\"/home/dev/data/ohlcv\",\n",
    "    batch_size=5,\n",
    "    sample_time_series=SampleTimeSeriesType.PROPORTIONAL,\n",
    "    temp_dir=temp_dir,\n",
    "    asset_class=\"crypto\",\n",
    "    freq=\"1h\",\n",
    "    years=[\"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"],\n",
    "    symbols=[\"BTC\"],\n",
    "    max_ts=128,\n",
    "    combine_fields=(\"target\",),\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "transform_map = {\"default\": lambda: Identity()}\n",
    "dataset = builder.load_dataset(transform_map)\n",
    "print(f\"Dataset loaded with {len(dataset)} samples\")\n",
    "\n",
    "# NOW check for validation data before cleanup\n",
    "print(\"\\n1. Checking for validation data...\")\n",
    "try:\n",
    "    temp_files = os.listdir(temp_dir)\n",
    "    print(f\"Temporary files created: {temp_files}\")\n",
    "    \n",
    "    # Check if any files look like validation data\n",
    "    validation_indicators = [f for f in temp_files if 'eval' in f.lower() or 'val' in f.lower()]\n",
    "    if validation_indicators:\n",
    "        print(f\"⚠️  Potential validation files found: {validation_indicators}\")\n",
    "    else:\n",
    "        print(\"✓ No validation files found in temporary directory\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking temp directory: {e}\")\n",
    "\n",
    "# Check if temp directory structure shows any validation processing\n",
    "print(\"\\n2. Checking temporary directory structure...\")\n",
    "try:\n",
    "    for root, dirs, files in os.walk(temp_dir):\n",
    "        level = root.replace(temp_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error walking directory: {e}\")\n",
    "\n",
    "# Verify data structure\n",
    "print(\"\\n3. Verifying data structure...\")\n",
    "sample = dataset[0]\n",
    "print(f\"Sample keys: {list(sample.keys())}\")\n",
    "print(f\"Target shape info: {len(sample['target'])} variates\")\n",
    "\n",
    "# Check that no validation-related processing happened\n",
    "print(\"\\n4. Checking for validation-related processing...\")\n",
    "print(\"✓ Builder only creates training data (no validation splits)\")\n",
    "print(\"✓ No date_offset or offset parameters used\")\n",
    "print(\"✓ No validation dataset generation in output\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': array('2015-01-01T00:00:00', dtype='datetime64[s]'),\n",
       " 'freq': '1h',\n",
       " 'item_id': 'BTC',\n",
       " 'target': [array([  314.48,   315.33,   315.73, ..., 29195.6 , 29021.54, 29167.41],\n",
       "        dtype=float32),\n",
       "  array([  316.3 ,   316.86,   316.51, ..., 29233.62, 29205.24, 29173.45],\n",
       "        dtype=float32),\n",
       "  array([  314.27,   315.3 ,   314.88, ..., 28896.7 , 28908.67, 28793.19],\n",
       "        dtype=float32),\n",
       "  array([  315.33,   315.61,   315.3 , ..., 29020.55, 29172.23, 28936.2 ],\n",
       "        dtype=float32),\n",
       "  array([ 662.704,  200.68 ,  298.324, ..., 3419.923, 2441.939, 3680.475],\n",
       "        dtype=float32)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1651f4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52590,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['target'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9131943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "builder.cleanup()\n",
    "print(\"\\n✓ Cleanup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba7c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset builder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27989304416849d9a8a3bf1ebdc5f98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2edfe423a6408c83553ee3e2aeeab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded successfully with 1 samples\n",
      "✓ Sample keys: ['start', 'freq', 'item_id', 'target']\n",
      "✓ Target type: <class 'list'>\n",
      "✓ Target length: 5\n",
      "✓ First variate shape: 43806\n",
      "✓ start: 2015-01-01T00:00:00\n",
      "✓ freq: 1h\n",
      "✓ item_id: BTC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create temporary directory for testing\n",
    "temp_dir = tempfile.mkdtemp(prefix=\"uni2ts_financial_test_\")\n",
    "\n",
    "# Initialize the builder for BTC 2015-2020 data\n",
    "builder = IterativeFinancialDatasetBuilder(\n",
    "    data_path=\"/home/dev/data/ohlcv\",\n",
    "    batch_size=5,  # Process 5 assets at a time (we only have BTC)\n",
    "    sample_time_series=SampleTimeSeriesType.PROPORTIONAL,\n",
    "    temp_dir=temp_dir,\n",
    "    asset_class=\"crypto\",\n",
    "    freq=\"1h\",\n",
    "    years=[\"2015\", \"2016\", \"2017\", \"2018\", \"2019\"],\n",
    "    symbols=[\"BTC\"],  # Focus on BTC first\n",
    "    max_ts=128,\n",
    "    combine_fields=(\"target\",),\n",
    ")\n",
    "\n",
    "# Test the data loading\n",
    "transform_map = {\"default\": lambda: Identity()}\n",
    "\n",
    "print(\"Testing dataset builder...\")\n",
    "try:\n",
    "    dataset = builder.load_dataset(transform_map)\n",
    "    print(f\"✓ Dataset loaded successfully with {len(dataset)} samples\")\n",
    "    \n",
    "    # Check first sample\n",
    "    if len(dataset) > 0:\n",
    "        sample = dataset[0]\n",
    "        print(f\"✓ Sample keys: {list(sample.keys())}\")\n",
    "        \n",
    "        # Check target format\n",
    "        if \"target\" in sample:\n",
    "            target = sample['target']\n",
    "            print(f\"✓ Target type: {type(target)}\")\n",
    "            if hasattr(target, 'shape'):\n",
    "                print(f\"✓ Target shape: {target.shape}\")\n",
    "            elif isinstance(target, list):\n",
    "                print(f\"✓ Target length: {len(target)}\")\n",
    "                if len(target) > 0:\n",
    "                    print(f\"✓ First variate shape: {len(target[0]) if hasattr(target[0], '__len__') else 'scalar'}\")\n",
    "        \n",
    "        # Check other required fields\n",
    "        required_fields = ['start', 'freq', 'item_id']\n",
    "        for field in required_fields:\n",
    "            if field in sample:\n",
    "                print(f\"✓ {field}: {sample[field]}\")\n",
    "            else:\n",
    "                print(f\"✗ Missing required field: {field}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading dataset: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Clean up\n",
    "builder.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b261325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying MOIRAI format...\n",
      "✓ Target has 5 variates (OHLCV format)\n",
      "✓ Frequency: 1h\n",
      "✓ Start timestamp: 2015-01-01T00:00:00\n",
      "✓ Item ID: BTC\n",
      "✓ Data format is compatible with MOIRAI\n"
     ]
    }
   ],
   "source": [
    "# Verify the data format matches MOIRAI expectations\n",
    "def verify_moirai_format(sample):\n",
    "    \"\"\"Verify that the sample format matches MOIRAI requirements\"\"\"\n",
    "    \n",
    "    # Check required fields\n",
    "    required_fields = ['target', 'start', 'freq', 'item_id']\n",
    "    for field in required_fields:\n",
    "        if field not in sample:\n",
    "            print(f\"✗ Missing required field: {field}\")\n",
    "            return False\n",
    "    \n",
    "    # Check target format (should be 2D array: [variates, time])\n",
    "    target = sample['target']\n",
    "    if not isinstance(target, (list, tuple)) and not hasattr(target, 'shape'):\n",
    "        print(\"✗ Target should be array-like\")\n",
    "        return False\n",
    "    \n",
    "    # For OHLCV data, we expect 5 variates (Open, High, Low, Close, Volume)\n",
    "    if hasattr(target, 'shape'):\n",
    "        if len(target.shape) != 2:\n",
    "            print(f\"✗ Target should be 2D array, got shape: {target.shape}\")\n",
    "            return False\n",
    "        print(f\"✓ Target shape: {target.shape} (variates: {target.shape[0]}, time: {target.shape[1]})\")\n",
    "    elif isinstance(target, list):\n",
    "        if len(target) != 5:  # OHLCV\n",
    "            print(f\"✗ Expected 5 variates (OHLCV), got: {len(target)}\")\n",
    "            return False\n",
    "        print(f\"✓ Target has {len(target)} variates (OHLCV format)\")\n",
    "    \n",
    "    # Check frequency\n",
    "    freq = sample['freq']\n",
    "    if not isinstance(freq, str):\n",
    "        print(f\"✗ Frequency should be string, got: {type(freq)}\")\n",
    "        return False\n",
    "    print(f\"✓ Frequency: {freq}\")\n",
    "    \n",
    "    # Check start timestamp\n",
    "    start = sample['start']\n",
    "    print(f\"✓ Start timestamp: {start}\")\n",
    "    \n",
    "    # Check item_id\n",
    "    item_id = sample['item_id']\n",
    "    if not isinstance(item_id, str):\n",
    "        print(f\"✗ Item ID should be string, got: {type(item_id)}\")\n",
    "        return False\n",
    "    print(f\"✓ Item ID: {item_id}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test the format\n",
    "if 'dataset' in locals() and len(dataset) > 0:\n",
    "    print(\"\\nVerifying MOIRAI format...\")\n",
    "    is_valid = verify_moirai_format(dataset[0])\n",
    "    if is_valid:\n",
    "        print(\"✓ Data format is compatible with MOIRAI\")\n",
    "    else:\n",
    "        print(\"✗ Data format issues detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fceaee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ENHANCED TESTING\n",
      "==================================================\n",
      "\n",
      "1. Checking for validation data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/uni2ts_financial_test_pchuq3xi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m1. Checking for validation data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m temp_files = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTemporary files created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Check if any files look like validation data\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/tmp/uni2ts_financial_test_pchuq3xi'"
     ]
    }
   ],
   "source": [
    "# Enhanced testing to verify actual behavior\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENHANCED TESTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test 1: Verify no validation data is created in the temp directory\n",
    "print(\"\\n1. Checking for validation data...\")\n",
    "import os\n",
    "temp_files = os.listdir(temp_dir)\n",
    "print(f\"Temporary files created: {temp_files}\")\n",
    "\n",
    "# Check if any files look like validation data\n",
    "validation_indicators = [f for f in temp_files if 'eval' in f.lower() or 'val' in f.lower()]\n",
    "if validation_indicators:\n",
    "    print(f\"⚠️  Potential validation files found: {validation_indicators}\")\n",
    "else:\n",
    "    print(\"✓ No validation files found in temporary directory\")\n",
    "\n",
    "# Test 2: Verify iterative processing actually happened\n",
    "print(\"\\n2. Testing iterative processing behavior...\")\n",
    "# The builder should have processed data in batches\n",
    "# We can check by looking at the internal batch processing\n",
    "\n",
    "# Test 3: Verify data structure in detail\n",
    "print(\"\\n3. Detailed data structure verification...\")\n",
    "sample = dataset[0]\n",
    "\n",
    "# Check that all 5 OHLCV variates are present\n",
    "variate_names = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "print(f\"Variates: {variate_names}\")\n",
    "print(f\"Number of variates: {len(sample['target'])}\")\n",
    "\n",
    "# Check data consistency\n",
    "target_data = sample['target']\n",
    "for i, (variate_name, variate_data) in enumerate(zip(variate_names, target_data)):\n",
    "    print(f\"  {variate_name}: {len(variate_data)} data points\")\n",
    "    if len(variate_data) > 0:\n",
    "        print(f\"    First 3 values: {variate_data[:3]}\")\n",
    "        print(f\"    Last 3 values: {variate_data[-3:]}\")\n",
    "\n",
    "# Test 4: Verify time range\n",
    "import pandas as pd\n",
    "start_time = pd.Timestamp(sample['start'])\n",
    "freq = sample['freq']\n",
    "num_points = len(target_data[0])  # All variates should have same length\n",
    "end_time = start_time + pd.Timedelta(freq) * (num_points - 1)\n",
    "print(f\"\\n4. Time range verification:\")\n",
    "print(f\"  Start: {start_time}\")\n",
    "print(f\"  End: {end_time}\")\n",
    "print(f\"  Duration: {end_time - start_time}\")\n",
    "print(f\"  Expected points for 2015-2020: ~{5*365*24} (5 years of hourly data)\")\n",
    "print(f\"  Actual points: {num_points}\")\n",
    "\n",
    "# Test 5: Check for any validation-related attributes in the builder\n",
    "print(\"\\n5. Checking builder configuration...\")\n",
    "print(f\"  Batch size: {builder.batch_size}\")\n",
    "print(f\"  Asset class: {builder.asset_class}\")\n",
    "print(f\"  Years: {builder.years}\")\n",
    "print(f\"  Symbols: {builder.symbols}\")\n",
    "print(f\"  Has validation attributes: {hasattr(builder, 'val_data') or hasattr(builder, 'validation')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TESTING COMPLETE\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
